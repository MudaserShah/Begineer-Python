{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to AI APIs for Beginners\n",
    "\n",
    "## Welcome to AI APIs!\n",
    "\n",
    "In our previous lecture, we learned about APIs and how to use the `requests` module in Python. Today, we're going to take that knowledge a step further and explore how to use two powerful AI APIs:\n",
    "\n",
    "1. **OpenAI API** - The technology behind ChatGPT and GPT\n",
    "2. **Google AI Studio API** - Google's advanced Gemini models\n",
    "\n",
    "By the end of this 20-minute lecture, you'll be able to:\n",
    "- Understand how to securely store and use API keys\n",
    "- Make basic calls to OpenAI's API with the latest GPT-4.1-mini model\n",
    "- Make basic calls to Google AI Studio's API\n",
    "- Create simple AI-powered applications\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are AI APIs?\n",
    "\n",
    "AI APIs (Application Programming Interfaces) allow your programs to access powerful artificial intelligence capabilities without having to build or train AI models yourself.\n",
    "\n",
    "Think of them as special services that can:\n",
    "- Generate human-like text\n",
    "- Answer questions\n",
    "- Summarize content\n",
    "- Translate languages\n",
    "- Create images\n",
    "- And much more!\n",
    "\n",
    "You simply send a request with your input, and the API returns the AI-generated result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "For this lecture, we assume you:\n",
    "- Have basic Python knowledge\n",
    "- Are familiar with the `requests` module from our previous lecture\n",
    "- Have a text editor to create a `.env` file\n",
    "\n",
    "Don't worry if some concepts seem new - we'll explain everything step by step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Keys and Environment Variables\n",
    "\n",
    "## What are API Keys?\n",
    "\n",
    "API keys are like special passwords that allow you to access and use an API service. When you make a request to an AI API, you need to include your API key so the service knows:\n",
    "\n",
    "1. Who you are\n",
    "2. Whether you have permission to use the service\n",
    "3. How to track your usage (many APIs have usage limits or costs)\n",
    "\n",
    "**Important:** API keys should be kept secret! If someone gets your API key, they could use the service while pretending to be you, potentially costing you money or using up your quota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Get API Keys\n",
    "\n",
    "For this lecture, you'll need to get API keys from both OpenAI and Google AI Studio:\n",
    "\n",
    "### OpenAI API Key:\n",
    "1. Go to [OpenAI's website](https://platform.openai.com/)\n",
    "2. Create an account or sign in\n",
    "3. Navigate to the API section\n",
    "4. Find your API key in the account settings\n",
    "\n",
    "### Google AI Studio API Key:\n",
    "1. Go to [Google AI Studio](https://aistudio.google.com/)\n",
    "2. Sign in with your Google account\n",
    "3. Click on \"Get API key\" and create a new key\n",
    "\n",
    "**Note:** Both services offer free tiers or credits for new users, but may require payment information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .env Files for API Keys\n",
    "\n",
    "A `.env` file is a simple text file that stores environment variables (like API keys) that your program can access. Using a `.env` file is a best practice for several reasons:\n",
    "\n",
    "1. **Security**: Keeps sensitive information out of your code\n",
    "2. **Portability**: Makes it easy to use different keys in different environments\n",
    "3. **Version Control**: Prevents API keys from being uploaded to GitHub or other repositories\n",
    "\n",
    "Let's see how to create and use a `.env` file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a .env file\n",
    "\n",
    "Create a new file named `.env` (note the dot at the beginning) in the same folder as your notebook or Python script. Add your API keys like this:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "GOOGLE_API_KEY=your_google_api_key_here\n",
    "```\n",
    "\n",
    "Replace `your_openai_api_key_here` and `your_google_api_key_here` with your actual API keys.\n",
    "\n",
    "**Important:** Never share this file with others or upload it to public repositories!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Install python-dotenv\n",
    "\n",
    "We need a package called `python-dotenv` to read our `.env` file. Let's install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Install the python-dotenv package\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load Environment Variables\n",
    "\n",
    "Now we can load our API keys from the `.env` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY loaded successfully.\n",
      "GOOGLE_API_KEY loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Function to get an API key by name\n",
    "def get_api_key(key_name):\n",
    "    try:\n",
    "        key = os.getenv(key_name)\n",
    "        if key:\n",
    "            print(f\"{key_name} loaded successfully.\")\n",
    "        else:\n",
    "            print(f\"{key_name} not found. Please check your .env file.\")\n",
    "        return key\n",
    "    except Exception as error:\n",
    "        print(f\"Something went wrong while loading {key_name}: {error}\")\n",
    "        return None\n",
    "\n",
    "# Load API keys\n",
    "openai_api_key = get_api_key(\"OPENAI_API_KEY\")\n",
    "google_api_key = get_api_key(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Happening in the Code Above?\n",
    "\n",
    "1. We import the `os` module, which lets us access environment variables\n",
    "2. We import the `load_dotenv` function from the `dotenv` module\n",
    "3. We call `load_dotenv()` to load all variables from our `.env` file into the environment\n",
    "4. We use `os.getenv(\"VARIABLE_NAME\")` to get each API key\n",
    "5. We check if the keys were loaded and print a confirmation message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Using Environment Variables Directly\n",
    "\n",
    "If you can't use a `.env` file (for example, in some online environments), you can set environment variables directly in your code, but this is less secure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use this method for testing or if .env files are not an option\n",
    "# Replace 'your_api_key_here' with your actual API keys\n",
    "\n",
    "# import os\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your_api_key_here\"  # Not recommended for production code\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your_api_key_here\"  # Not recommended for production code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the OpenAI API\n",
    "\n",
    "## What is OpenAI?\n",
    "\n",
    "OpenAI is the company behind popular AI models like GPT-4.1 and ChatGPT. Their API gives you access to these powerful language models for your applications.\n",
    "\n",
    "With the OpenAI API, you can:\n",
    "- Generate text responses to prompts\n",
    "- Create conversational AI assistants\n",
    "- Summarize long documents\n",
    "- Translate languages\n",
    "- And much more!\n",
    "\n",
    "Let's learn how to use it in Python with the latest GPT-4.1-mini model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install the OpenAI Python Package\n",
    "\n",
    "First, we need to install the OpenAI Python package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (1.58.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mhari\\appdata\\local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# Install the OpenAI Python package\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Up the OpenAI Client\n",
    "\n",
    "Now we'll create an OpenAI client using our API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import the OpenAI client\n",
    "from openai import OpenAI\n",
    "\n",
    "# Create a client instance using our API key\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# If the API key is loaded correctly, this will print a success message\n",
    "if client:\n",
    "    print(\"OpenAI client created successfully!\")\n",
    "else:\n",
    "    print(\"Failed to create OpenAI client. Check your API key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make a Simple Text Completion Request with GPT-4.1-mini\n",
    "\n",
    "Let's start with a basic example - asking the AI to generate a response to a prompt using the latest GPT-4.1-mini model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Explain what an API is in one sentence.\n",
      "Response: An API (Application Programming Interface) is a set of rules and protocols that allows different software applications to communicate and interact with each other.\n"
     ]
    }
   ],
   "source": [
    "def get_ai_response(prompt):\n",
    "    \"\"\"\n",
    "    Function to get a response from OpenAI's GPT-4.1-mini model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text prompt to send to the AI\n",
    "        \n",
    "    Returns:\n",
    "        str: The AI's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a completion request\n",
    "        response = client.chat.completions.create(\n",
    "            # Specify the latest GPT-4.1-mini model\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            # Provide the messages in the conversation\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            # Set maximum length of the response\n",
    "            max_tokens=150,\n",
    "            # Control randomness (0 = deterministic, 1 = very random)\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Extract and return the response text\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test our function with a simple prompt\n",
    "prompt = \"Explain what an API is in one sentence.\"\n",
    "response = get_ai_response(prompt)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Code\n",
    "\n",
    "Let's break down what's happening in the code above:\n",
    "\n",
    "1. We define a function `get_ai_response()` that takes a prompt as input\n",
    "2. Inside a try-except block (for error handling), we:\n",
    "   - Call `client.chat.completions.create()` to send our request to OpenAI\n",
    "   - Specify the model to use (`gpt-4.1-mini`, which is the latest model)\n",
    "   - Provide messages in a specific format with roles (system and user)\n",
    "   - Set parameters like `max_tokens` (maximum response length) and `temperature` (creativity level)\n",
    "3. We extract the response text from `response.choices[0].message.content`\n",
    "4. We test the function with a simple prompt and print the results\n",
    "\n",
    "**Note:** The `messages` parameter uses a specific format with roles:\n",
    "- `system`: Instructions for how the AI should behave\n",
    "- `user`: The actual prompt from the user\n",
    "- `assistant`: Previous responses from the AI (for multi-turn conversations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Multi-Turn Conversation with GPT-4.1-mini\n",
    "\n",
    "Now let's try a more advanced example - a multi-turn conversation with the AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is a Python list?\n",
      "AI: A Python list is a built-in data structure that allows you to store an ordered collection of items. These items can be of any data type, such as numbers, strings, or even other lists. Lists are mutable, which means you can change their content after creation (add, remove, or modify elements).\n",
      "\n",
      "Here are some key features of Python lists:\n",
      "\n",
      "- **Ordered**: The items have a defined order, and that order will not change unless you explicitly reorder the list.\n",
      "- **Mutable**: You can modify the list after it is created.\n",
      "- **Heterogeneous**: You can store items of different data types in the same list.\n",
      "- **Indexed**: You can access elements by their position (index) starting from 0\n",
      "\n",
      "User: Can you show me an example of list comprehension?\n",
      "AI: Certainly! List comprehension is a concise way to create lists in Python. It allows you to generate a new list by applying an expression to each item in an existing iterable (like a list or range), optionally filtering elements with a condition.\n",
      "\n",
      "### Example\n",
      "\n",
      "Let's say you want to create a list of squares of numbers from 0 to 9.\n",
      "\n",
      "```python\n",
      "squares = [x**2 for x in range(10)]\n",
      "print(squares)\n",
      "```\n",
      "\n",
      "**Output:**\n",
      "\n",
      "```\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "- `x**2` is the expression to compute the square of `x`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def chat_with_ai(conversation_history):\n",
    "    \"\"\"\n",
    "    Function to have a conversation with OpenAI's GPT-4.1 model.\n",
    "    \n",
    "    Args:\n",
    "        conversation_history (list): List of message dictionaries with 'role' and 'content'\n",
    "        \n",
    "    Returns:\n",
    "        str: The AI's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a completion request with the conversation history\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=conversation_history,\n",
    "            max_tokens=150,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # Extract the response text\n",
    "        ai_response = response.choices[0].message.content\n",
    "        \n",
    "        # Add the AI's response to the conversation history\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "        \n",
    "        return ai_response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Initialize a conversation\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"}\n",
    "]\n",
    "\n",
    "# First user message\n",
    "user_message = \"What is a Python list?\"\n",
    "conversation.append({\"role\": \"user\", \"content\": user_message})\n",
    "print(f\"User: {user_message}\")\n",
    "\n",
    "# Get AI response\n",
    "response = chat_with_ai(conversation)\n",
    "print(f\"AI: {response}\")\n",
    "\n",
    "# Second user message\n",
    "user_message = \"Can you show me an example of list comprehension?\"\n",
    "conversation.append({\"role\": \"user\", \"content\": user_message})\n",
    "print(f\"\\nUser: {user_message}\")\n",
    "\n",
    "# Get AI response\n",
    "response = chat_with_ai(conversation)\n",
    "print(f\"AI: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Multi-Turn Conversations\n",
    "\n",
    "In the code above:\n",
    "\n",
    "1. We define a function `chat_with_ai()` that takes a conversation history as input\n",
    "2. The conversation history is a list of message dictionaries, each with a `role` and `content`\n",
    "3. We send the entire conversation history to OpenAI with each request\n",
    "4. After getting a response, we add it to the conversation history\n",
    "5. This allows the AI to remember previous messages and maintain context\n",
    "\n",
    "This approach is powerful because it allows you to create chatbots or assistants that can remember previous interactions and maintain a coherent conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Error Handling for OpenAI API\n",
    "\n",
    "When working with APIs, it's important to handle errors properly. Let's look at some common errors and how to handle them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Response: Python is a versatile programming language used for a wide variety of applications, including:\n",
      "\n",
      "1. **Web Development:** Building websites and web applications using frameworks like Django and Flask.\n",
      "2. **Data Science and Analysis:** Analyzing data, performing statistical operations, and visualizing data with libraries such as pandas, NumPy, and Matplotlib.\n",
      "3. **Machine Learning and Artificial Intelligence:** Developing AI models and machine learning algorithms using libraries like TensorFlow, Keras, and scikit-learn.\n",
      "4. **Automation and Scripting:** Automating repetitive tasks, writing scripts to manage files, and interact with various software.\n",
      "5. **Software Development:** Creating desktop applications and tools.\n",
      "6. **Game Development:** Developing games using libraries such as Pyg\n"
     ]
    }
   ],
   "source": [
    "def safe_ai_request(prompt):\n",
    "    \"\"\"\n",
    "    Function to safely make a request to the OpenAI API with proper error handling.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text prompt to send to the AI\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success, result) where success is a boolean and result is the response or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if API key is available\n",
    "        if not openai_api_key:\n",
    "            return False, \"API key not found. Please check your .env file.\"\n",
    "        \n",
    "        # Create a completion request\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=150\n",
    "        )\n",
    "        \n",
    "        # Extract and return the response text\n",
    "        return True, response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle different types of errors\n",
    "        error_message = str(e)\n",
    "        \n",
    "        if \"Unauthorized\" in error_message:\n",
    "            return False, \"Authentication error: Your API key may be invalid.\"\n",
    "        elif \"Rate limit\" in error_message:\n",
    "            return False, \"Rate limit exceeded: You're making too many requests. Please wait and try again.\"\n",
    "        elif \"insufficient_quota\" in error_message:\n",
    "            return False, \"Quota exceeded: You've used up your API quota or credits.\"\n",
    "        else:\n",
    "            return False, f\"Error: {error_message}\"\n",
    "\n",
    "# Test with a simple prompt\n",
    "success, result = safe_ai_request(\"What is Python used for?\")\n",
    "\n",
    "if success:\n",
    "    print(f\"Success! Response: {result}\")\n",
    "else:\n",
    "    print(f\"Failed: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common OpenAI API Errors\n",
    "\n",
    "When using the OpenAI API, you might encounter these common errors:\n",
    "\n",
    "1. **Authentication errors**: Invalid or missing API key\n",
    "2. **Rate limit errors**: Too many requests in a short time\n",
    "3. **Quota errors**: You've used up your API credits or exceeded your billing limit\n",
    "4. **Invalid request errors**: Incorrect parameters or formatting\n",
    "5. **Server errors**: Issues on OpenAI's side\n",
    "\n",
    "Good error handling makes your applications more robust and provides better user experiences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Google AI Studio API\n",
    "\n",
    "## What is Google AI Studio?\n",
    "\n",
    "Google AI Studio provides access to Google's powerful Gemini models through an easy-to-use API. These models can understand and generate text, images, and more, allowing you to build sophisticated AI-powered applications.\n",
    "\n",
    "With the Google AI Studio API, you can:\n",
    "- Generate text responses to prompts\n",
    "- Create conversational AI assistants\n",
    "- Analyze and understand content\n",
    "- Build multimodal applications\n",
    "\n",
    "Let's learn how to use it in Python with the latest available models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install the Google Generative AI Python Package\n",
    "\n",
    "First, we need to install the official Google Generative AI Python package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Google Generative AI Python package\n",
    "!pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Up the Google AI Studio Client\n",
    "\n",
    "Now we'll create a client using our API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhari\\AppData\\Local\\anaconda3\\envs\\marahel_eval\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Gemini models:\n",
      "- models/gemini-1.0-pro-vision-latest\n",
      "- models/gemini-pro-vision\n",
      "- models/gemini-1.5-pro-latest\n",
      "- models/gemini-1.5-pro-001\n",
      "- models/gemini-1.5-pro-002\n",
      "- models/gemini-1.5-pro\n",
      "- models/gemini-1.5-flash-latest\n",
      "- models/gemini-1.5-flash-001\n",
      "- models/gemini-1.5-flash-001-tuning\n",
      "- models/gemini-1.5-flash\n",
      "- models/gemini-1.5-flash-002\n",
      "- models/gemini-1.5-flash-8b\n",
      "- models/gemini-1.5-flash-8b-001\n",
      "- models/gemini-1.5-flash-8b-latest\n",
      "- models/gemini-1.5-flash-8b-exp-0827\n",
      "- models/gemini-1.5-flash-8b-exp-0924\n",
      "- models/gemini-2.5-pro-exp-03-25\n",
      "- models/gemini-2.5-pro-preview-03-25\n",
      "- models/gemini-2.5-flash-preview-04-17\n",
      "- models/gemini-2.5-flash-preview-04-17-thinking\n",
      "- models/gemini-2.5-pro-preview-05-06\n",
      "- models/gemini-2.0-flash-exp\n",
      "- models/gemini-2.0-flash\n",
      "- models/gemini-2.0-flash-001\n",
      "- models/gemini-2.0-flash-exp-image-generation\n",
      "- models/gemini-2.0-flash-lite-001\n",
      "- models/gemini-2.0-flash-lite\n",
      "- models/gemini-2.0-flash-preview-image-generation\n",
      "- models/gemini-2.0-flash-lite-preview-02-05\n",
      "- models/gemini-2.0-flash-lite-preview\n",
      "- models/gemini-2.0-pro-exp\n",
      "- models/gemini-2.0-pro-exp-02-05\n",
      "- models/gemini-exp-1206\n",
      "- models/gemini-2.0-flash-thinking-exp-01-21\n",
      "- models/gemini-2.0-flash-thinking-exp\n",
      "- models/gemini-2.0-flash-thinking-exp-1219\n",
      "- models/gemini-embedding-exp-03-07\n",
      "- models/gemini-embedding-exp\n",
      "- models/gemini-2.0-flash-live-001\n",
      "\n",
      "Google AI Studio client configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import the Google Generative AI library\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure the API with your key\n",
    "genai.configure(api_key=google_api_key)\n",
    "\n",
    "# List available models to verify our setup\n",
    "try:\n",
    "    models = genai.list_models()\n",
    "    gemini_models = [model.name for model in models if 'gemini' in model.name.lower()]\n",
    "    print(\"Available Gemini models:\")\n",
    "    for model in gemini_models:\n",
    "        print(f\"- {model}\")\n",
    "    print(\"\\nGoogle AI Studio client configured successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring Google AI Studio client: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make a Simple Text Generation Request\n",
    "\n",
    "Let's start with a basic example - asking the AI to generate a response to a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Explain what an API is in one sentence.\n",
      "Response: An API is a set of rules and specifications that allows different software systems to communicate and exchange data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_gemini_response(prompt):\n",
    "    \"\"\"\n",
    "    Function to get a response from Google's Gemini model.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text prompt to send to the AI\n",
    "        \n",
    "    Returns:\n",
    "        str: The AI's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Select a Gemini model (use models from the list_models output)\n",
    "        model = genai.GenerativeModel('models/gemini-1.5-flash-8b-latest')\n",
    "        \n",
    "        # Generate a response\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        # Return the response text\n",
    "        return response.text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test our function with a simple prompt\n",
    "prompt = \"Explain what an API is in one sentence.\"\n",
    "response = get_gemini_response(prompt)\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Code\n",
    "\n",
    "Let's break down what's happening in the code above:\n",
    "\n",
    "1. We define a function `get_gemini_response()` that takes a prompt as input\n",
    "2. Inside a try-except block (for error handling), we:\n",
    "   - Create a GenerativeModel instance with the 'gemini-pro' model\n",
    "   - Call `model.generate_content()` to send our prompt to Gemini\n",
    "   - Extract the response text with `response.text`\n",
    "3. We test the function with a simple prompt and print the results\n",
    "\n",
    "The Google AI Studio API is designed to be simple and straightforward to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Using Different Gemini Models\n",
    "\n",
    "Google AI Studio offers different Gemini models for different tasks. Let's try using another model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Explain the difference between supervised and unsupervised machine learning, and give an example of each.\n",
      "Response: The key difference between supervised and unsupervised machine learning lies in the nature of the data used to train the model.\n",
      "\n",
      "**Supervised Learning:**\n",
      "\n",
      "In supervised learning, the algorithm is trained on a dataset that includes both the input features and the corresponding desired output or target variable.  The algorithm learns to map inputs to outputs by identifying patterns in the training data.  Think of it like a student learning from a teacher.\n",
      "\n",
      "* **Training Data:** Includes input features and the correct output.\n",
      "* **Goal:** To predict the output for new, unseen inputs.\n",
      "* **Example:**  Predicting house prices.  You have a dataset with features like size, location, number of bedrooms, and the corresponding sale price. The algorithm learns the relationship between these features and the price to predict the price of a new house based on its characteristics.\n",
      "\n",
      "**Unsupervised Learning:**\n",
      "\n",
      "In unsupervised learning, the algorithm is trained on a dataset that only includes input features, without any corresponding output variable. The algorithm learns to identify patterns, structures, and relationships within the data itself. Think of it like a student exploring a complex topic without a predetermined answer key.\n",
      "\n",
      "* **Training Data:** Only includes input features.\n",
      "* **Goal:** To discover hidden patterns, structures, or groupings within the data.\n",
      "* **Example:** Customer segmentation. You have data on customer demographics, purchase history, and website activity. The algorithm groups similar customers together based on their shared characteristics without being explicitly told which groups exist.  This can help businesses tailor marketing campaigns to different customer segments.\n",
      "\n",
      "**In summary:**\n",
      "\n",
      "| Feature | Supervised Learning | Unsupervised Learning |\n",
      "|---|---|---|\n",
      "| **Training Data** | Input features + desired output | Input features only |\n",
      "| **Goal** | Predict output for new inputs | Discover patterns/structures in data |\n",
      "| **Example** | Predicting house prices, image classification | Customer segmentation, anomaly detection |\n",
      "\n",
      "\n",
      "These are broad categories, and there are variations within each.  For example, supervised learning can involve different types of prediction tasks like classification (e.g., classifying emails as spam or not spam) or regression (e.g., predicting house prices).  Unsupervised learning can involve techniques like clustering (grouping similar data points) or dimensionality reduction (reducing the number of variables while preserving important information).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_gemini_flash_response(prompt):\n",
    "    \"\"\"\n",
    "    Function to get a response from Google's Gemini Flash model (faster responses).\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text prompt to send to the AI\n",
    "        \n",
    "    Returns:\n",
    "        str: The AI's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Select the Gemini Flash model for faster responses\n",
    "        model = genai.GenerativeModel('models/gemini-1.5-flash-8b-latest')\n",
    "        \n",
    "        # Generate a response\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        # Return the response text\n",
    "        return response.text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test with a more complex prompt\n",
    "complex_prompt = \"Explain the difference between supervised and unsupervised machine learning, and give an example of each.\"\n",
    "response = get_gemini_flash_response(complex_prompt)\n",
    "\n",
    "print(f\"Prompt: {complex_prompt}\")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create a Chat Conversation\n",
    "\n",
    "Now let's create a multi-turn conversation with the Gemini model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is a Python dictionary?\n",
      "Gemini: A Python dictionary is an unordered collection of key-value pairs.  It's one of Python's built-in data structures.\n",
      "\n",
      "* **Key:**  Each key is unique within the dictionary and must be an immutable data type (e.g., string, number, tuple).\n",
      "\n",
      "* **Value:**  A value can be of any data type (e.g., string, number, list, tuple, another dictionary).\n",
      "\n",
      "* **Unordered:**  The order in which key-value pairs are stored is not guaranteed and can change.  If you need a specific order, use an `OrderedDict`.\n",
      "\n",
      "* **Mutable:**  Dictionaries can be modified after creation (you can add, remove, or change key-value pairs).\n",
      "\n",
      "**Example:**\n",
      "\n",
      "```python\n",
      "student = {\n",
      "    \"name\": \"Alice\",\n",
      "    \"age\": 20,\n",
      "    \"major\": \"Computer Science\",\n",
      "    \"grades\": [95, 88, 92]\n",
      "}\n",
      "\n",
      "print(student)  # Output: {'name': 'Alice', 'age': 20, 'major': 'Computer Science', 'grades': [95, 88, 92]}\n",
      "\n",
      "print(student[\"name\"])  # Output: Alice\n",
      "\n",
      "student[\"age\"] = 21  # Modifying a value\n",
      "print(student[\"age\"])  # Output: 21\n",
      "\n",
      "student[\"city\"] = \"New York\" #Adding a new key-value pair\n",
      "print(student)\n",
      "\n",
      "```\n",
      "\n",
      "**Key characteristics and uses:**\n",
      "\n",
      "* **Fast lookups:**  Finding a value associated with a specific key is very efficient (typically O(1) time complexity).\n",
      "\n",
      "* **Storing data:**  Dictionaries are excellent for representing structured data where you want to access information by meaningful names (keys).\n",
      "\n",
      "* **Representing data structures:**  Dictionaries can be nested to create more complex data structures (like representing objects in an object-oriented way).\n",
      "\n",
      "* **Mapping:** Dictionaries implement the mapping abstract data type.\n",
      "\n",
      "\n",
      "**Important considerations:**\n",
      "\n",
      "* **Keys must be immutable:**  You can't use lists or dictionaries as keys directly because they are mutable.  Tuples, however, are immutable and can be used as keys.\n",
      "\n",
      "* **Keys must be unique:**  Duplicate keys are not allowed.  If you try to assign a value to a key that already exists, the old value associated with that key will be overwritten.\n",
      "\n",
      "User: Can you show me an example of creating and using one?\n",
      "Gemini: ```python\n",
      "# Creating a dictionary to store information about a car\n",
      "\n",
      "car = {\n",
      "    \"make\": \"Toyota\",\n",
      "    \"model\": \"Camry\",\n",
      "    \"year\": 2023,\n",
      "    \"color\": \"Silver\",\n",
      "    \"mileage\": 10000,\n",
      "    \"features\": [\"automatic transmission\", \"sunroof\", \"GPS navigation\"]\n",
      "}\n",
      "\n",
      "# Accessing values using keys\n",
      "\n",
      "print(f\"The car's make is: {car['make']}\")  # Output: The car's make is: Toyota\n",
      "print(f\"The car's year is: {car['year']}\")   # Output: The car's year is: 2023\n",
      "\n",
      "# Accessing a value from a list inside the dictionary\n",
      "print(f\"The car has these features: {car['features']}\") #Output: The car has these features: ['automatic transmission', 'sunroof', 'GPS navigation']\n",
      "print(f\"The car's first feature is: {car['features'][0]}\") #Output: The car's first feature is: automatic transmission\n",
      "\n",
      "# Adding a new key-value pair\n",
      "car[\"price\"] = 25000\n",
      "print(f\"The car's price is: {car['price']}\") #Output: The car's price is: 25000\n",
      "\n",
      "\n",
      "# Updating an existing value\n",
      "car[\"mileage\"] = 15000\n",
      "print(f\"The car's updated mileage is: {car['mileage']}\") #Output: The car's updated mileage is: 15000\n",
      "\n",
      "#  Checking if a key exists (using 'in')\n",
      "if \"model\" in car:\n",
      "    print(\"The model key exists.\")  # Output: The model key exists.\n",
      "\n",
      "# Looping through all key-value pairs (using a loop)\n",
      "print(\"\\nCar details:\")\n",
      "for key, value in car.items():\n",
      "  print(f\"{key}: {value}\")\n",
      "\n",
      "\n",
      "#  Deleting a key-value pair\n",
      "del car[\"color\"]  \n",
      "print(\"\\nCar details after deleting color:\")\n",
      "for key, value in car.items():\n",
      "    print(f\"{key}: {value}\")\n",
      "\n",
      "#Handling a non-existent key gracefully (using get())\n",
      "print(f\"The car's engine type is: {car.get('engine type', 'Not found')}\")  # Output: The car's engine type is: Not found\n",
      "\n",
      "\n",
      "#Empty dictionary\n",
      "empty_dict = {}\n",
      "print(empty_dict) #Output: {}\n",
      "```\n",
      "\n",
      "This example demonstrates various dictionary operations:\n",
      "\n",
      "* **Creating a dictionary:**  Using curly braces `{}` and key-value pairs.\n",
      "* **Accessing values:** Using the key in square brackets `[]`.\n",
      "* **Adding new key-value pairs.**\n",
      "* **Updating existing values.**\n",
      "* **Checking if a key exists.**\n",
      "* **Iterating through key-value pairs.**\n",
      "* **Deleting a key-value pair.**\n",
      "* **Handling missing keys with `get()`** â€“ this is safer than directly accessing a key that might not exist.\n",
      "* **Empty Dictionary**\n",
      "\n",
      "\n",
      "This comprehensive example showcases practical ways to interact with Python dictionaries, including adding, updating, accessing, and iterating through their content.  It also includes error handling. Remember to run this code to see the output in your Python environment. Remember to use f-strings for cleaner string formatting.\n",
      "\n",
      "\n",
      "```\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def chat_with_gemini():\n",
    "    \"\"\"\n",
    "    Function to create a chat session with Gemini.\n",
    "    \n",
    "    Returns:\n",
    "        object: A chat session object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Select the Gemini Pro model\n",
    "        model = genai.GenerativeModel('models/gemini-1.5-flash-8b-latest')\n",
    "        \n",
    "        # Create a chat session\n",
    "        chat = model.start_chat(history=[])\n",
    "        \n",
    "        return chat\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating chat: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Create a chat session\n",
    "chat = chat_with_gemini()\n",
    "\n",
    "import time\n",
    "\n",
    "if chat:\n",
    "    # First message\n",
    "    response = chat.send_message(\"What is a Python dictionary?\")\n",
    "    print(\"User: What is a Python dictionary?\")\n",
    "    print(f\"Gemini: {response.text}\\n\")\n",
    "    time.sleep(10) # sleep to avoid the rate limit!\n",
    "    # Second message (notice how the context is maintained)\n",
    "    response = chat.send_message(\"Can you show me an example of creating and using one?\")\n",
    "    print(\"User: Can you show me an example of creating and using one?\")\n",
    "    print(f\"Gemini: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Chat Sessions\n",
    "\n",
    "In the code above:\n",
    "\n",
    "1. We define a function `chat_with_gemini()` that creates a chat session\n",
    "2. We use `model.start_chat()` to initialize a new chat session\n",
    "3. We use `chat.send_message()` to send messages to the chat session\n",
    "4. The chat session automatically maintains the conversation history\n",
    "5. Each response includes the AI's reply in the `text` property\n",
    "\n",
    "This approach is simpler than OpenAI's because you don't need to manually manage the conversation history - the chat session object does it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Configuring Generation Parameters\n",
    "\n",
    "You can customize how Gemini generates responses by setting various parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creative response (high temperature = 0.9):\n",
      "From logic's seed, a code takes flight,\n",
      "With zeros, ones, a world takes light.\n",
      "A million lines, a whispered plea,\n",
      "To make the machine, obey thee.\n",
      "Errors arise, a tangled thread,\n",
      "But patience sought, the problem's spread.\n",
      "Refined and polished, clear and bright,\n",
      "The program runs, a shining light.\n",
      "\n",
      "\n",
      "Focused response (low temperature = 0.2):\n",
      "Lines of code, a whispered plea,\n",
      "To circuits deep, for tasks to be.\n",
      "Logic flows, a digital stream,\n",
      "A world of thought, a waking dream.\n",
      "\n",
      "From zero, one, a pattern spun,\n",
      "A world of wonder, newly won.\n",
      "The program runs, a silent grace,\n",
      "A digital dance in time and space.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_customized_response(prompt, temperature=0.7, max_output_tokens=256):\n",
    "    \"\"\"\n",
    "    Function to get a customized response from Gemini.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text prompt to send to the AI\n",
    "        temperature (float): Controls randomness (0.0 to 1.0)\n",
    "        max_output_tokens (int): Maximum length of the response\n",
    "        \n",
    "    Returns:\n",
    "        str: The AI's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create generation config\n",
    "        generation_config = {\n",
    "            \"temperature\": temperature,\n",
    "            \"max_output_tokens\": max_output_tokens,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 40,\n",
    "        }\n",
    "        \n",
    "        # Select model with custom configuration\n",
    "        model = genai.GenerativeModel(\n",
    "            model_name=\"models/gemini-1.5-flash-8b-latest\",\n",
    "            generation_config=generation_config\n",
    "        )\n",
    "        \n",
    "        # Generate response\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        return response.text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test with different temperatures\n",
    "prompt = \"Write a short poem about programming.\"\n",
    "\n",
    "print(\"Creative response (high temperature = 0.9):\")\n",
    "creative_response = get_customized_response(prompt, temperature=0.9)\n",
    "print(creative_response)\n",
    "\n",
    "print(\"\\nFocused response (low temperature = 0.2):\")\n",
    "focused_response = get_customized_response(prompt, temperature=0.2)\n",
    "print(focused_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Generation Parameters\n",
    "\n",
    "The key parameters you can adjust include:\n",
    "\n",
    "1. **temperature**: Controls randomness (0.0 to 1.0)\n",
    "   - Lower values (e.g., 0.2) make responses more focused and deterministic\n",
    "   - Higher values (e.g., 0.9) make responses more creative and varied\n",
    "   \n",
    "2. **max_output_tokens**: Maximum length of the response\n",
    "   - Limits how long the generated text can be\n",
    "   \n",
    "3. **top_p** and **top_k**: Control which words the model considers\n",
    "   - Advanced parameters that affect token selection during generation\n",
    "   \n",
    "Adjusting these parameters lets you control the style and length of the AI's responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Error Handling for Google AI Studio API\n",
    "\n",
    "Let's implement proper error handling for Google AI Studio API calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Response: Python boasts a rich set of features that contribute to its popularity and versatility.  Here are some of the key features:\n",
      "\n",
      "**Fundamental Features:**\n",
      "\n",
      "* **Readability and Simplicity:** Python's syntax is designed to be clear and concise, resembling plain English. This makes it easier to learn, read, and maintain code compared to many other languages.  Keywords are English words, and the code is often quite self-documenting.\n",
      "\n",
      "* **Interpreted Language:**  Python code is executed line by line by an interpreter, unlike compiled languages that translate the entire code into machine code upfront.  This makes development faster and debugging easier (especially in interactive mode).\n",
      "\n",
      "* **Dynamically Typed:** Python doesn't require explicit type declarations for variables. The interpreter infers the type during execution. This adds flexibility but can lead to runtime errors if type mismatches occur.\n",
      "\n",
      "* **Object-Oriented:** Python supports object-oriented programming (OOP) concepts like classes, objects, inheritance, and polymorphism. This allows for structured and reusable code.\n",
      "\n",
      "**Key Strengths:**\n",
      "\n",
      "* **Large and Active Community:** A vast community of developers provides extensive support, libraries, and resources. This translates to readily available solutions and help when needed.\n",
      "\n",
      "* **Extensive Libraries and Frameworks:** Python's rich ecosystem offers a wide range of pre-built libraries for various tasks, including web development (Django, Flask), data science (NumPy, Pandas, Scikit-learn), machine learning (TensorFlow, PyTorch), and more.  This reduces the need to write code from scratch and allows for rapid prototyping.\n",
      "\n",
      "* **Cross-Platform Compatibility:** Python code can run on various operating systems (Windows, macOS, Linux) without significant modifications, thanks to its interpreter.\n",
      "\n",
      "* **Large Ecosystem:** A huge amount of pre-built software exists, meaning there are likely pre-written solutions to your problems. This further reduces development time.\n",
      "\n",
      "* **Versatile Use Cases:** Python's versatility extends across various domains, including web development, data science, machine learning, scripting, automation, and more.  It's not limited to a specific application.\n",
      "\n",
      "* **Excellent for Beginners:** Python's readability and ease of use make it an excellent first programming language for beginners.  It's a good way to get started with programming concepts.\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "* **Performance (compared to compiled languages):** Python's interpreted nature can result in slower execution speeds compared to compiled languages for computationally intensive tasks. However, optimization techniques and libraries often address this limitation in many practical applications.\n",
      "\n",
      "\n",
      "These features combine to make Python a powerful and popular language for a wide range of applications, from small scripts to large-scale projects.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def safe_gemini_request(prompt):\n",
    "    \"\"\"\n",
    "    Function to safely make a request to the Google AI Studio API with proper error handling.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text prompt to send to the AI\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success, result) where success is a boolean and result is the response or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if API key is available\n",
    "        if not google_api_key:\n",
    "            return False, \"API key not found. Please check your .env file.\"\n",
    "        \n",
    "        # Generate response\n",
    "        model = genai.GenerativeModel('models/gemini-1.5-flash-8b-latest')\n",
    "        response = model.generate_content(prompt)\n",
    "        \n",
    "        # Return the response text\n",
    "        return True, response.text\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_message = str(e)\n",
    "        \n",
    "        if \"invalid_api_key\" in error_message.lower() or \"unauthorized\" in error_message.lower():\n",
    "            return False, \"Authentication error: Your API key may be invalid.\"\n",
    "        elif \"quota\" in error_message.lower():\n",
    "            return False, \"Quota exceeded: You've used up your API quota or credits.\"\n",
    "        elif \"rate\" in error_message.lower():\n",
    "            return False, \"Rate limit exceeded: You're making too many requests. Please wait and try again.\"\n",
    "        elif \"blocked\" in error_message.lower() or \"safety\" in error_message.lower():\n",
    "            return False, \"Content blocked: Your prompt may have triggered safety filters.\"\n",
    "        elif \"not found\" in error_message.lower():\n",
    "            return False, \"Model not found: The specified model may not be available.\"\n",
    "        else:\n",
    "            return False, f\"Error: {error_message}\"\n",
    "\n",
    "# Test with a simple prompt\n",
    "success, result = safe_gemini_request(\"What are the main features of Python?\")\n",
    "\n",
    "if success:\n",
    "    print(f\"Success! Response: {result}\")\n",
    "else:\n",
    "    print(f\"Failed: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Google AI Studio API Errors\n",
    "\n",
    "When using the Google AI Studio API, you might encounter these common errors:\n",
    "\n",
    "1. **Authentication errors**: Invalid or missing API key\n",
    "2. **Safety filter blocks**: Prompts that trigger safety filters\n",
    "3. **Quota errors**: You've used up your API quota or credits\n",
    "4. **Rate limit errors**: Too many requests in a short time\n",
    "5. **Model not found errors**: The specified model is not available\n",
    "6. **Server errors**: Issues on Google's side\n",
    "\n",
    "The code above handles these common error types and provides user-friendly error messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Exercises\n",
    "\n",
    "Now that you've learned how to use both the OpenAI and Google AI Studio APIs, let's practice with some exercises. Try completing these on your own:\n",
    "\n",
    "## Exercise 1: Simple Question Answering\n",
    "\n",
    "Create a function that takes a question as input and returns answers from both OpenAI and Google AI Studio for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is machine learning?\n",
      "\n",
      "OpenAI GPT-4.1: Machine learning is a branch of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform tasks without being explicitly programmed. Instead of following fixed instructions, machine learning systems learn patterns and make decisions based on data. This allows them to improve their performance on a given task over time through experience.\n",
      "\n",
      "In essence, machine learning involves feeding data into a model, which then identifies patterns or relationships within the data. The model can then use what it has learned to make predictions, classify information, or take actions based on new input data. Common types of machine learning include:\n",
      "\n",
      "1. **Supervised learning**: The model is trained on labeled data, meaning the input comes with the correct output, and the goal is for\n",
      "\n",
      "Google AI Studio: Machine learning is a type of artificial intelligence (AI) that allows software applications to become more accurate in predicting outcomes without being explicitly programmed.  Instead of relying on hard-coded rules, machine learning algorithms use statistical methods to identify patterns and relationships in data, and then use these patterns to make decisions or predictions on new data.\n",
      "\n",
      "Essentially, the computer learns from data rather than being told what to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_ai_responses(question):\n",
    "    \"\"\"\n",
    "    Function to compare responses from OpenAI and Google AI Studio.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The question to ask both AIs\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (openai_response, gemini_response)\n",
    "    \"\"\"\n",
    "    # Get response from OpenAI GPT-4.1\n",
    "    openai_response = get_ai_response(question)\n",
    "    \n",
    "    # Get response from Google AI Studio\n",
    "    gemini_response = get_gemini_response(question)\n",
    "    \n",
    "    return openai_response, gemini_response\n",
    "\n",
    "# Example usage:\n",
    "question = \"What is machine learning?\"\n",
    "openai_answer, gemini_answer = compare_ai_responses(question)\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"OpenAI GPT-4.1: {openai_answer}\\n\")\n",
    "print(f\"Google AI Studio: {gemini_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Create a Simple AI Assistant\n",
    "\n",
    "Create a simple assistant that can answer questions about Python programming using either OpenAI or Google AI Studio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How do I read a file in Python?\n",
      "\n",
      "OpenAI Answer:\n",
      "Reading a file in Python is simple and straightforward. You can use the built-in `open()` function to open a file, and then read its contents using methods like `.read()`, `.readline()`, or `.readlines()`. After you're done, it's important to close the file to free up system resources, or better yet, use a `with` statement which handles closing automatically.\n",
      "\n",
      "Hereâ€™s a beginner-friendly example of how to read the entire contents of a file:\n",
      "\n",
      "```python\n",
      "# Open the file in read mode ('r')\n",
      "with open('example.txt', 'r') as file:\n",
      "    content = file.read()  # Read the entire file into a string\n",
      "\n",
      "print(content)  # Print the file contents\n",
      "```\n",
      "\n",
      "###\n",
      "\n",
      "Google AI Studio Answer:\n",
      "Reading a file in Python is a common task.  There are several ways, depending on what you want to do with the file's contents.\n",
      "\n",
      "**1. Reading the entire file into a string:**\n",
      "\n",
      "This is useful if you need to process the entire file's content at once.\n",
      "\n",
      "```python\n",
      "def read_file_to_string(filename):\n",
      "    \"\"\"Reads the entire contents of a file into a string.\n",
      "\n",
      "    Args:\n",
      "        filename: The name of the file to read.\n",
      "\n",
      "    Returns:\n",
      "        The content of the file as a string, or None if the file doesn't exist.\n",
      "        Raises an exception if there's an error reading the file.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        with open(filename, 'r') as file:\n",
      "            file_content = file.read()\n",
      "            return file_content\n",
      "    except FileNotFoundError:\n",
      "        print(f\"Error: File '{filename}' not found.\")\n",
      "        return None\n",
      "    except Exception as e:\n",
      "        print(f\"An error occurred: {e}\")\n",
      "        return None\n",
      "\n",
      "# Example usage:\n",
      "filename = \"my_file.txt\"\n",
      "content = read_file_to_string(filename)\n",
      "\n",
      "if content:\n",
      "  print(content)\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **`with open(filename, 'r') as file:`:** This is the recommended way to open a file.  The `with` statement ensures the file is automatically closed even if errors occur.  The `'r'` indicates that you're opening the file for reading.\n",
      "* **`file.read()`:** This reads the entire file's content into a string.\n",
      "* **`try...except` block:**  This is crucial for handling potential errors, such as the file not being found.\n",
      "\n",
      "\n",
      "**2. Reading line by line:**\n",
      "\n",
      "This is often preferred for files with a large amount of data, as it avoids loading everything into memory at once.\n",
      "\n",
      "```python\n",
      "def read_file_line_by_line(filename):\n",
      "    \"\"\"Reads a file line by line.\n",
      "\n",
      "    Args:\n",
      "        filename: The name of the file to read.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        with open(filename, 'r') as file:\n",
      "            for line in file:\n",
      "                # Process each line here (e.g., print it):\n",
      "                print(line.strip())  # .strip() removes leading/trailing whitespace\n",
      "    except FileNotFoundError:\n",
      "        print(f\"Error: File '{filename}' not found.\")\n",
      "    except Exception as e:\n",
      "        print(f\"An error occurred: {e}\")\n",
      "\n",
      "\n",
      "# Example usage:\n",
      "filename = \"my_file.txt\"\n",
      "read_file_line_by_line(filename)\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* The `for line in file:` loop iterates through each line of the file.  Crucially, each line *includes* the newline character (`\\n`).\n",
      "* `.strip()` is used to remove any leading or trailing whitespace (spaces, tabs, newlines) from each line. This is good practice for many data processing tasks.\n",
      "\n",
      "**Important considerations:**\n",
      "\n",
      "* **Error handling:**  Always include `try...except` blocks to handle potential errors like the file not being found or permission issues.\n",
      "* **File encoding:** If your file uses a different encoding (like UTF-8), you may need to specify it when opening the file:  `open(filename, 'r', encoding='utf-8')`\n",
      "\n",
      "\n",
      "**Example `my_file.txt` (for the examples):**\n",
      "\n",
      "```\n",
      "This is the first line.\n",
      "This is the second line.\n",
      "  This line has extra whitespace.\n",
      "```\n",
      "\n",
      "\n",
      "Remember to create a file named `my_file.txt` in the same directory as your Python script with some text in it before running the code.  These examples will help you get started with reading different kinds of files in Python. Choose the method that best suits how you intend to use the data in your file. Remember to replace `\"my_file.txt\"` with the actual name of your file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def python_assistant(question, use_openai=True):\n",
    "    \"\"\"\n",
    "    Function to create a Python programming assistant using either OpenAI or Google AI Studio.\n",
    "    \n",
    "    Args:\n",
    "        question (str): The Python-related question to ask\n",
    "        use_openai (bool): Whether to use OpenAI (True) or Google AI Studio (False)\n",
    "        \n",
    "    Returns:\n",
    "        str: The AI's response\n",
    "    \"\"\"\n",
    "    # Create a more specific prompt for better results\n",
    "    prompt = f\"\"\"You are a helpful Python programming assistant. \n",
    "    Please answer the following question about Python programming:\n",
    "    {question}\n",
    "    \n",
    "    If the question involves code, please include example code in your answer.\n",
    "    Keep your explanation clear and beginner-friendly.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get response from the selected API\n",
    "    if use_openai:\n",
    "        return get_ai_response(prompt)  # Uses OpenAI GPT-4.1\n",
    "    else:\n",
    "        return get_gemini_response(prompt)  # Uses Google AI Studio\n",
    "\n",
    "# Example usage:\n",
    "question = \"How do I read a file in Python?\"\n",
    "answer_openai = python_assistant(question, use_openai=True)\n",
    "answer_gemini = python_assistant(question, use_openai=False)\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"OpenAI Answer:\\n{answer_openai}\\n\")\n",
    "print(f\"Google AI Studio Answer:\\n{answer_gemini}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Create Your Own Project\n",
    "\n",
    "Now it's your turn to create something with these APIs! Here are some project ideas:\n",
    "\n",
    "1. **Language Translator**: Create a function that translates text between languages using AI\n",
    "2. **Code Explainer**: Build a tool that explains what a piece of code does\n",
    "3. **Study Helper**: Create a flashcard generator that creates questions and answers on a topic\n",
    "4. **Story Generator**: Build a tool that generates short stories based on user prompts\n",
    "\n",
    "Choose one idea or come up with your own, and start building!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Congratulations! You've learned how to:\n",
    "\n",
    "1. Securely store and use API keys with `.env` files\n",
    "2. Make basic calls to the OpenAI API with the latest GPT-4.1 model\n",
    "3. Make basic calls to the Google AI Studio API with the latest Gemini models\n",
    "4. Handle errors and customize AI responses\n",
    "5. Build simple applications with AI capabilities\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To continue learning about AI APIs, you can:\n",
    "\n",
    "1. Explore more advanced features of these APIs (like image generation or analysis)\n",
    "2. Learn about other AI APIs (like Anthropic's Claude or Stability AI's image generation)\n",
    "3. Build more complex applications that combine multiple APIs\n",
    "4. Study the ethical considerations of using AI in applications\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [OpenAI API Documentation](https://platform.openai.com/docs/)\n",
    "- [Google AI Studio Documentation](https://ai.google.dev/docs)\n",
    "- [Python-dotenv Documentation](https://pypi.org/project/python-dotenv/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marahel_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
